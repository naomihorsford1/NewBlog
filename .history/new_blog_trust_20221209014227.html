<!DOCTYPE html>
<html lang=en>
    <head>
        <link rel="stylesheet" href="style.css">
        <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous"> 
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous"> 
        <meta charset="utf-8">
        <title>Independent Study - Data Visualization and Measuring Trust</title>
    </head>
    <body>
        <!-- Navigation -->
        
        <nav>
            <h1 class="navTitle"><strong>Data Vis & Trust</strong></h1>
            <a href="#">Home | </a>
            <a href="#c">Abstract |</a>
            <a href="#introduction">Intro |</a>
            <a href="#relatedWorks"> Related Work|</a>
            <a href="#goal"> Goal |<a>
            <a href="#experiment"> Experiment |</a>
            <a href="#future">Future</a>
        </nav>
        

        <!-- Name of Website -->
        <div class="section" id="landing">
            <h1 class="bodyTitle"><strong>Data Visualization and Measuring Trust</strong></h1>
            <img src="./docs:/landingimage2.png" alt="Welcome Image" id = "landingimage">
        </div>
        
        <br>
        <br>
    
            
        <!-- Abstract -->
        <div class="section" id="abstract">
        <h3>Abstract</h3>
        <p>
            Trust has many different meanings, yet it is essential in many disciplines. The data visualization discipline is no exception. The crucial factor is whether or not a user believes or has confidence in a visualization. After the user makes that decision, the question becomes how do you measure the trust in that data visualization? We present a research study on trust in visualizations measured using a survey with Likert scales and its results. We have also outlined the study's limitations and provided numerous future research directions.

        <p>
        </div>

        <!-- Intro -->
        <div class="section" id="introduction">
        <h3>Introduction</h3>
        <p>
            Trust is a word that has many different meanings in different contexts. The Oxford English Dictionary defines trust as "to have confidence in somebody; to believe that somebody is good, sincere, honest, etc." In the field of social science, Diego Gambetta defined trust as "he described trust as the subjective probability with which a person (or a group) assesses that another person (or a group) will perform a particular action, with this subjective probability influencing a person's own actions" (Morrone & Ranuzzi, 2009, p. 8). According to related works in the information visualization field, "trust is the user's implicit or explicit tendency to rely on a visualization and to build on the information displayed" (Mayr, Hynek, Salisu, & Windhager, 2019, p.1). 
        <p>
        
        <p>
            Today, trust in data visualizations is a current and hot topic. Trust is an essential concept in data visualization because it can help avoid the spread of misconception and confusion. The motive behind this study is to understand and measure trust in terms of data visualization. Other disciplines research trust thoroughly. However, there is very little research done on trust in data visualization. Most of the research done in this area of trust is recent. Furthermore, trust has been measured in other disciplines using measures like the prisoner's dilemma and the classic trust games, but measuring trust in data visualizations is even more sparsely researched. Measuring trust is vital in the data visualization community because trust was identified "as one of the top-10 challenges for visual analytics". (Mayr, Hynek, Salisu, & Windhager, 2019, p.1). Yet, trust is a complex concept to measure because it is multi-dimensional. Trust has many different aspects, such as understanding, creditability, and the user's behavioral intentions. Also, a user's trust in data visualizations can change over time, which adds complexity of time to this concept. In addition to trust being a complex concept, visualizations have many components, such as wording, colors, sourcing, and layout. The computer science and data visualization disciplines do not have a standard definition, system of design, tool, or measure for trust. Therefore, the answer to trust in the data visualization community is still being discovered. There has yet to be a universal quantitative measure for trust in data visualizations. This exact issue has led to this research project.
        </p>
        </div>

        <!-- Related Works -->
        <div class="section" id="relatedWorks">
        <h3>Related Works</h3>
        <p>
             In related works under the search "data visualization and trust," many works recognized trust as a big issue in the data visualization community. However, none of the works mentioned a universal measurement for trust that can be used with the different image categories for data visualizations. Also, they emphasized the need for universal design principles for data visualization and its community. In addition, there were common themes of transparency, recall, clarity, and biases. In related works of "How to measure trust in data," trust is measured differently across disciplines through interpersonal and institutional connections. Many works analyze previous ways trust has been measured and look into the future for new ways to measure this concept. Nonetheless, these works emphasize that there is no consensus on the definition of trust or a standard metric for trust for computer scientists and data visualization researchers. There were very few related works under the search of "design and trust," but one of the works wrote about interpersonal trust and reciprocation in user interface design. 

        </p>
        </div>

        <!-- Research Goal -->
        <div class="section" id="goal">
        <h3>Research Goal</h3>
        <p>
            This research project aimed to develop an instrument that measures how well people read, understand, and trust data visualization. Also, the goal of this project was to quantitatively measure trust, a qualitative measure, in different categories of data visualizations. The intent of the results of this survey will help develop better visual communication tools.
        </p>
        </div>

        <!-- Experiment -->
        <div class="section" id="experiment">
        <h3>Experiment</h3>
        <h4>Explanation of Experiment</h4>
        <p>
            This experiment is an online survey where on the left-hand side of the screen, the participant sees an image of a data visualization that they can zoom in on details, and on the right-hand side of the screen, there were 11 questions answered using a Likert scale. The completed survey has 30 images of data visualizations, with each image having 11 required Likert scale questions. The 5-point Likert scale ranged from Strongly Disagree to Disagree to Neither to Agree to Strongly Agree. The images of the data visualizations came from a database called MASSVIS,  a Massachusetts (Massive) Visualization Dataset. This database is one of the largest real-world visualization databases. It is a collection of various online publication venues, including government reports, infographic blogs, news media websites, and scientific journals. The variety of visualizations gives a sense of the real world, where we encounter many different categories of visualizations. This database is a collection of over 5,000 static data visualizations. These visualizations contain visualization-type information, annotations, memorability scores, eye movement, and labels. 
        </p>
        <p>
            This survey defines trust through four types of questions: credibility, understanding, future actions, and motive. Under credibility, there were two questions; (1) I believe the visualization shows real data and (2) I am familiar with the topic or data this visualization presents. Under understanding, there was one question; (3) I understand what this visualization is trying to tell me. Under future action, there were two questions, (4) I would rely on the facts in this visualization, and (5) I would feel confident using the information to make a decision. Under motive (genre), there were six questions, (6) This is a narrative visualization (telling a story or sharing something that happened), (7) This is a descriptive visualization (sharing details about people, places, or things), (8) This is a persuasive visualization (getting a point across or trying to convince the viewer), (9) This is an expository visualization (explaining or informing about a particular topic), (10) This is a creative visualization (an artistic expression with data), (11) This is a technical visualization (presenting specialized or scientific data). This survey took participants an average of 38 minutes to complete the survey.
        </p>
        <img src="./docs:/screenshotSurvey.png" alt="Screenshoot of Survey for Experiment" class = "photos">
        <label>Screenshoot of Survey for Experiment</label>

        <table>
            <thead>

            </thead>
            <tbody>
                <tr>
                    <td>
                        <img src="./docs:/economist_daily_chart_2.png" alt="Example" class = "photosTables"> 
                    </td>
                    <td>
                        <img src="./docs:/treasuryA1.png" alt="Example" alt="Example" width="65%" height="65%"> 
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="./docs:/v480_n7378_1_f1.png" alt="Example" class = "photosTables"> 
                    </td>
                    <td>
                        <img src="./docs:/visMost9.png" alt="Example" width="65%" height="65%"> 
                    </td>
                </tr>
            </tbody>
        </table>
        <label>Examples of Graphs: News, Government, Science, Infograph</label>

        <h4>Demographics</h4>
        <p>
            In terms of demographics, this experiment has 10 English-speaking participants. Four participants identified as male, and six participants identified as female. Specifically, the average age of the participant group is 34 years old. The participants' education ranges from high school to doctorate. There was one participant with a high school degree, six participants with a bachelor's degree, two participants with a master's degree, and one participant with a doctorate. 
        </p>

        <h4>Results</h4>
        <p>
            The results of the ten surveys are analyzed using six types of graphs. These graphs include an overall response bar chart, a stacked bar chart of each image type, a heat map, subplots categorized by question and image category, bar charts with responses by image category, and a bar chart of responses by questions and question types. The heat map and the response by question and type of question can be grouped by the survey questions (questions 1 through 11) or by question type (creditability, understanding, future actions, and motive). Looking at the axes on the folder axis, vis1, vis2, and vis3 come from the infographic blogs part of the MASSIV database. Looking at the legend, specifically the Avg. Response (Numerical), this numerical system is used in the Heat Map and Average Response by Question & Category graphs. Each response value from the Likert scale was assigned a numeric value from -2 to 2; Strongly disagree is -2, disagree is -1, neither is 0, agree is 1, and strongly agree is 2. These numeric values created average values for the overall response. With these averages, we can see how positively or negatively participants felt about questions, categories of data visualization images, and types of questions.
        </p>

        <p>
            When analyzing the survey results, we found that 51% of overall responses were positive, meaning slightly over half of the participants answered either Agree or Strongly Agree, no matter the question or category of image. 
        </p>
        
        <img src="./docs:/overall.png" alt="Overall" class = "photos">
        <label>Overall responses to the survey</label>

        <hr4>Science</hr4>
        <p>
            However, participants had the most negative responses when answering the science category of the data visualizations. When looking at all data visualization image categories except for science, there is a general upward trend in bar graphs, where there are smaller percentages of people who Strongly Disagree in relation to higher percentages of people who Agree. However, in the science category, you can see a general downward trend of the highest percentage of Strongly Disagree to the smallest percentage of Strongly Agree. Moreover, in the responses by question and question type graph, the science category has the most average negative response of -0.6. In terms of question types for science, understanding has the most negative responses. Within the category of understanding, question 3 had the most significant negative average out of any question of any image category. However, in general, participants were positive about question 1 and question 10. Although science has a positive average for question 1, showing on average, participants believed the visualization showed real data, its average response value was the lowest out of all six image categories for question 1. In question 11, which states, "This is a technical visualization (presenting specialized or scientific data)," it was the opposite. Also, in question 11, science has the highest or most positive average response.
        </p>

        <img src="./docs:/heatmap-qType.png" alt="Heat Map of Question Types" class = "photos">
        <label>Heat Map of Question Types</label>
        <img src="./docs:/science.png" alt="Stacked Chart of the Science Category" class = "photos">
        <label>Stacked Chart of the Science Category</label>
        <img src="./docs:/responseByVisCateogry-qType.png" alt="Response by Image Category by Question Type" class = "photos">
        <label>Response by Image Category by Question Type</label>
        <img src="./docs:/avgResponseby-Question.png" alt="Average Response by Question and Image Category" class = "photos">
        <label>Average Response by Question and Image Category</label>

        <hr4>News</hr4>
        <p>
            In contrast, participants have the most positive response to the news category, specifically understanding. In particular, looking at question 3 again, it had the most significant number of positive strongly agrees. However, question 5, a future action question, had the most positive responses, including both strongly agree and agree. In conclusion, understanding could be a driving characteristic of trust across many data visualization image categories. 
        </p>

        <img src="./docs:/likert3-allCategoriesSubplot.png" alt="Question 3 Responses with all Image Categories" class = "photos">
        <label>Question 3 Responses with all Image Categories</label>
        <img src="./docs:/news.png" alt="Stacked Chart of the News Category" class = "photos">
        <label>Stacked Chart of the News Category</label>

        <hr4>Limitations</hr4>
        <p>
            It is essential to recognize the limitations of this experiment. With only 10 participants in this experiment, there is a possibility of inaccurate predictions or assumptions based on a limited number of data points. In terms of the images of data visualization, the database these data visualizations came from does not give information about the sources of each data visualization image. In addition, a few of the data visualizations were in other languages, which the participants were not fluent. In those cases, the participants relied only on visuals to answer the survey questions.
        </p>
        </div>

        <!-- Park Info-->
        <div class="section" id="future">
        <h3>Future Work</h3>
        <p>
            These experiment results can lead to more profound research on the lack of trust in data visualization. Is there a correlation between understanding of scientific topics and trust in science data visualization? What aspects of the visualization affected the understanding or responses to question 3? 
        </p>

        <img src="../docs:/heatmap-question.png" alt="Heat Map of Questions" class = "photos">
        <label>Heat Map of Questions</label>

        <p>
            These questions and results could lead to the next steps taken for this research project. In addition, these results have raised other questions related to these other aspects of the data visualization image that relate to trust, such as language, word count, color, source, and historical context. First, an element of data visualizations that should be further researched is language. Some participants commented that some of the data visualization images were in Spanish, which they could not understand. Therefore, adding data about language to the current project would help create a deeper understanding of trust and choice of language. The second and the third aspect of data visualization that should be further researched is the word count and color use of each data visualization. Other related works mention that the number of words and colors used in visualizations affects the content's digestibility, affecting a user's trust in the visualization. In a related work, "Fooled by beautiful data: Visualization aesthetics bias trust in science, news, and social media," it stated, "we manipulated graph beauty and demonstrated that beauty causally affected trust (Study 5)" (Lin & Thornton, 2021, p.2). Data on whether the data visualization is colorblind friendly is vital to understand the visualization's correlation with trust better. The fourth aspect of data visualizations that should be further researched is the source of the visualization. In further experiments, data on where the visualization came from should be collected. Related works state the source of the visualization is an essential factor in whether the audience trusts the data visualization. Particularly today, in the age of COVID-19 and a polarized political climate, future work should analyze what social media platforms or news outlets the data visualizations came from. This information will help deepen our understanding of trust concerning data visualizations posted on social media platforms. A related work states, "visualizations from particular sources were judged to be more or less trustworthy" (Rettberg, 2020, p. 136). Finally, the fifth aspect of data visualizations that should be researched is historical context. In future research, dates of when the visualization was published should be collected. This information would help inform whether historical events affected people's trust in specific data visualizations. The sourcing of the data visualization is the more promising path compared to the others. The reputation of the data source is a vital indicator of trust, even though it is one of the aspects of the data visualization that was not in the MASSIV database.

        </p>

        <h3>Acknowledgements</h3>
        <p>
            I want to thank Professor Alvitta Ottley and Saugat Pandey for mentoring me throughout this research study and providing valuable feedback through all stages of this research project. I gratefully acknowledge the guidance I received from these researchers at our institution, Washington University in St. Louis. 
        </p>
        <img src="https://marcomm.wustl.edu/wp-content/uploads/2015/07/Washington_University_SealRGB200-oqtfje.png" alt="WashU Logo">


        <h3>References</h3>
        <p>
            Bauer, P. C., & Freitag, M. (2018). Measuring trust. The Oxford handbook of social and political trust, 15
        </p>
        <p>
            Borgo, R., & Edwards, D. J. (2020). The Development of Visualization Psychology Analysis Tools to Account for Trust. arXiv preprint arXiv:2009.13200.
        </p>

        <p>
            Christen, M., Brugger, P., & Fabrikant, S. I. (2021). Susceptibility of domain experts to color manipulation indicate a need for design principles in data visualization. PloS one, 16(2), e0246479.
        </p>

        <p>
            Chuang, J., Ramage, D., Manning, C., & Heer, J. (2012, May). Interpretation and trust: Designing model-driven visualizations for text analysis. In Proceedings of the SIGCHI conference on human factors in computing systems (pp. 443-452).
        </p>

        <p>
            6. Dasgupta, A., Lee, J. Y., Wilson, R., Lafrance, R. A., Cramer, N., Cook, K., & Payne, S. (2016). Familiarity vs trust: A comparative study of domain scientists' trust in visual analytics and conventional analysis methods. IEEE transactions on visualization and computer graphics, 23(1), 271-280.
        </p>

        <p>
            Elhamdadi, H., Gaba, A., Kim, Y. S., & Xiong, C. (2022). How Do We Measure Trust in Visual Data Communication?. arXiv preprint arXiv:2209.14276.
        </p>

        <p>
            Elhamdadi, H., Padilla, L., & Xiong, C. (2022). Using Processing Fluency as a Metric of Trust in Scatterplot Visualizations. arXiv preprint arXiv:2209.14340.
        </p>

        <p>
            Hawlitschek, F., Jansen, L. E., Lux, E., Teubner, T., & Weinhardt, C. (2016, January). Colors and trust: The influence of user interface design on trust and reciprocity. In 2016 49th Hawaii International Conference on System Sciences (HICSS)(pp. 590-599). IEEE.
        </p>

        <p>
            Khvatova, T., Block, M., Zhukov, D., & Lesko, S. (2016). How to measure trust: the percolation model applied to intra-organisational knowledge sharing networks. Journal of Knowledge Management.
        </p>

        <p>
            Kim, Y. S., Reinecke, K., & Hullman, J. (2017). Data through others' eyes: The impact of visualizing others' expectations on visualization interpretation. IEEE transactions on visualization and computer graphics, 24(1), 760-769.

        </p>

        <p>
            Kong, H. K., Liu, Z., & Karahalios, K. (2019, May). Trust and recall of information across varying degrees of title-visualization misalignment. In Proceedings of the 2019 CHI conference on human factors in computing systems (pp. 1-13).

        </p>
            Lewicki, R. J., & Brinsfield, C. (2012). Measuring trust beliefs and behaviours. Handbook of research methods on trust, 29.

        <p>
            
        </p>
            Lin, C., & Thornton, M. A. (2021). Fooled by beautiful data: Visualization aesthetics bias trust in science, news, and social media.

        <p>
            
        </p>
            Matheus, R., Janssen, M., & Maheshwari, D. (2020). Data science empowering the     public: Data-driven dashboards for transparent and accountable decision-making in smart cities. Government Information Quarterly, 37(3), 101284.

        <p>
            
        </p>
            Mayr, E., Hynek, N., Salisu, S., & Windhager, F. (2019). Trust in Information Visualization. In TrustVis@ EuroVis (pp. 25-29).

        <p>
            
        </p>
            Moore, J. (2017). Data visualization in support of executive decision making. Interdisciplinary Journal of Information, Knowledge, and Management, 12, 125.

        <p>
            
        </p>
            Morrone, A., Tontoranelli, N., & Ranuzzi, G. (2009). How good is trust?: Measuring trust and its role for the progress of societies.

        <p>
            Peck, E. M., Ayuso, S. E., & El-Etr, O. (2019, May). Data is personal: Attitudes and perceptions of data visualization in rural pennsylvania. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (pp. 1-12).
        </p>

        <p>
            Rettberg, J. W. (2020). 2. Ways of knowing with data visualizations. Data visualization in society, 35
        </p>

        <p>
            Sacha, D., Senaratne, H., Kwon, B. C., Ellis, G., & Keim, D. A. (2015). The role of uncertainty, awareness, and trust in visual analytics. IEEE transactions on visualization and computer graphics, 22(1), 240-249.
        </p>

        <p>
            Stephen Boyd Davis, Olivia Vane & Florian Kr√§utli (2021) Can I believe what I see? Data visualization and trust in the humanities, Interdisciplinary Science Reviews, 46:4, 522-546, DOI: 10.1080/03080188.2021.1872874

        </p>

        <p>
            Trajkova, M., Alhakamy, A. A., Cafaro, F., Vedak, S., Mallappa, R., & Kankara, S. R. (2020, September). Exploring casual covid-19 data visualizations on Twitter: Topics and challenges. In Informatics (Vol. 7, No. 3, p. 35). MDPI.

        </p>

        <p>
            Xiong, C., Padilla, L., Grayson, K., & Franconeri, S. (2019). Examining the components of trust in map-based visualizations. In 1st EuroVis Workshop on Trustworthy Visualization, TrustVis 2019 (pp. 19-23). The Eurographics Association.

        </p>





        </p>

        </div>
    
    
        
    </body>
</html>